{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs for hate speech.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OlwOMXv9XRP"
      },
      "source": [
        "TODO: add explanation on whats going on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "w4GMTCxhOwO4",
        "outputId": "19279aaa-df76-4209-b293-b120e217e8ce"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "df_dav = pd.read_csv('/content/df_davs.csv', sep=' ')\n",
        "df_dav = df_dav.drop([\"hate_speech\", \"count\", \"offensive_language\", \"neither\"], axis = 1)\n",
        "df_dav=df_dav.reindex(columns=['tweet', 'class'])\n",
        "df_dav"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a woman you shouldnt complain about cleani...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>boy dats coldtyga dwn bad for cuffin dat hoe ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dawg RT You ever fuck a bitch and she start t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she look like a tranny</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The shit you hear about me might be true or i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>yous a muthafin lie right His TL is trash Now ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>youve gone and broke the wrong heart baby and ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>young buck wanna eat dat nigguh like I aint fu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>Ruffled Ntac Eileen Dahlia Beautiful color com...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  class\n",
              "0       As a woman you shouldnt complain about cleani...      2\n",
              "1       boy dats coldtyga dwn bad for cuffin dat hoe ...      1\n",
              "2       Dawg RT You ever fuck a bitch and she start t...      1\n",
              "3                                 she look like a tranny      1\n",
              "4       The shit you hear about me might be true or i...      1\n",
              "...                                                  ...    ...\n",
              "24778  yous a muthafin lie right His TL is trash Now ...      1\n",
              "24779  youve gone and broke the wrong heart baby and ...      2\n",
              "24780  young buck wanna eat dat nigguh like I aint fu...      1\n",
              "24781              youu got wild bitches tellin you lies      1\n",
              "24782  Ruffled Ntac Eileen Dahlia Beautiful color com...      2\n",
              "\n",
              "[24783 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rSWvF_bmxDI2",
        "outputId": "2d94bd9f-c7d1-469c-9760-ca624ea5e450"
      },
      "source": [
        "df_was = pd.read_csv('/content/df_was.csv', sep=' ')\n",
        "df_was[\"class_label\"] = df_was['class_label'].fillna(\"none\")\n",
        "df_was['class_label'].loc[(df_was['class_label'] == \"racism\")] = 0\n",
        "df_was['class_label'].loc[(df_was['class_label'] == \"sexism\")] = 1\n",
        "df_was['class_label'].loc[(df_was['class_label'] == \"none\")] = 2\n",
        "df_was['text'] = df_was['text'].astype(str)\n",
        "df_was"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drasko they didnt cook half a bird you idiot mkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>of course you were born in serbiayoure as fuck...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>These girls are the equivalent of the irritati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>At least youre only a tiny bit racist Im not ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2738</th>\n",
              "      <td>is above the national average wage PLUS its t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2739</th>\n",
              "      <td>its a great website use it omg you are right ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2740</th>\n",
              "      <td>this person thinks there is no wage gap smh N...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2741</th>\n",
              "      <td>Patriarchy will expel me if I divulge that I ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2742</th>\n",
              "      <td>Womens Studies Learn how to tell other women ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2743 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text class_label\n",
              "0      Drasko they didnt cook half a bird you idiot mkr           0\n",
              "1     Hopefully someone cooks Drasko in the next ep ...           0\n",
              "2     of course you were born in serbiayoure as fuck...           0\n",
              "3     These girls are the equivalent of the irritati...           0\n",
              "4      At least youre only a tiny bit racist Im not ...           0\n",
              "...                                                 ...         ...\n",
              "2738   is above the national average wage PLUS its t...           1\n",
              "2739   its a great website use it omg you are right ...           1\n",
              "2740   this person thinks there is no wage gap smh N...           1\n",
              "2741   Patriarchy will expel me if I divulge that I ...           1\n",
              "2742   Womens Studies Learn how to tell other women ...           1\n",
              "\n",
              "[2743 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y21A6SzvP7wk"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFKZ6jfDEFye"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad4T8-VQQJpD"
      },
      "source": [
        "X_train, X_valid, Y_train, Y_valid= train_test_split(df_dav['tweet'].tolist(),\n",
        "                                                      df_dav['class'].tolist(),\n",
        "                                                      test_size=0.3)\n",
        "train_data =list(zip(Y_train,X_train))\n",
        "valid_data =list(zip(Y_valid,X_valid))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HJW26w9Qbjg"
      },
      "source": [
        "tzr = get_tokenizer('basic_english')\n",
        "def torch_tokenizer(iterator):\n",
        "  for _, text in iterator:\n",
        "        yield tzr(text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA06mVvQRST-"
      },
      "source": [
        "dataset_copy = train_data\n",
        "transformed = build_vocab_from_iterator(torch_tokenizer(dataset_copy), specials=[\"<unk>\"])\n",
        "transformed.set_default_index(transformed[\"<unk>\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFRtxRY4R91H"
      },
      "source": [
        "text_to_index = lambda x: transformed(tzr(x))\n",
        "label_trans = lambda x: int(x) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEVlYFvXS-ih",
        "outputId": "47379e55-634d-48df-f554-3179c138b44a"
      },
      "source": [
        "text_to_index('hello world')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1899, 329]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtpcJFATKhl"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class CNNModel1(nn.Module):\n",
        "\n",
        "    def __init__(self, transformer_size, dim_in, dim_out):\n",
        "        super(CNNModel1, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(transformer_size, dim_in, sparse=True)\n",
        "        self.lin1 = nn.Linear(dim_in, 64)\n",
        "        self.lin2 = nn.Linear(64,16)\n",
        "        self.lin3 = nn.Linear(16, dim_out)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        r = 0.5\n",
        "        self.embedding.weight.data.uniform_(r, r)\n",
        "        nn.init.xavier_uniform_(self.lin1.weight)\n",
        "        nn.init.zeros_(self.lin1.bias)\n",
        "        nn.init.kaiming_normal_(self.lin2.weight)\n",
        "        nn.init.zeros_(self.lin2.bias)\n",
        "        self.lin3.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.lin3.bias)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = self.relu(self.lin1(embedded))\n",
        "        x = self.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V02wf8h8F328"
      },
      "source": [
        "class CNNModel2(nn.Module):\n",
        "      def __init__(self, transformer_size, dim_in, dim_out):\n",
        "        super(CNNModel2, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(transformer_size, dim_in, sparse=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_1 = torch.nn.Linear(dim_in, 100)\n",
        "        self.linear_2 = torch.nn.Linear(100, 64)\n",
        "        self.linear_3 = torch.nn.Linear(64, 16)\n",
        "        self.linear_4 = torch.nn.Linear(16, dim_out)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.init_weights()\n",
        "\n",
        "      def init_weights(self):\n",
        "          r = 0.5\n",
        "          self.embedding.weight.data.uniform_(r, r)\n",
        "          nn.init.xavier_uniform_(self.linear_1.weight)\n",
        "          nn.init.zeros_(self.linear_1.bias)\n",
        "          nn.init.kaiming_normal_(self.linear_2.weight)\n",
        "          nn.init.zeros_(self.linear_2.bias)\n",
        "          self.linear_3.weight.data.uniform_(-r, r)\n",
        "          nn.init.zeros_(self.linear_3.bias)\n",
        "          self.linear_4.weight.data.uniform_(-r, r)\n",
        "          nn.init.zeros_(self.linear_4.bias)\n",
        "\n",
        "      def forward(self, text, offsets):\n",
        "          embedded = self.embedding(text, offsets)\n",
        "          x = self.relu(self.linear_1(embedded))\n",
        "          x = self.relu(self.linear_2(x))\n",
        "          x = self.dropout(self.linear_3(x))\n",
        "          x = self.linear_4(x)\n",
        "          return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODIdYJEW21In"
      },
      "source": [
        "class CNNModel3(torch.nn.Module):\n",
        "    def __init__(self, transformer_size, dim_in, dim_out):\n",
        "        super(CNNModel3, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(transformer_size, dim_in, sparse=True)\n",
        "        self.max_pool2d = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.batch_norm = torch.nn.BatchNorm1d(num_features=64)\n",
        "        self.linear_1 = torch.nn.Linear(dim_in, 128)\n",
        "        self.linear_2 = torch.nn.Linear(64, dim_out)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        r = 0.5\n",
        "        self.embedding.weight.data.uniform_(r, r)\n",
        "        nn.init.kaiming_normal_(self.linear_2.weight)\n",
        "        nn.init.zeros_(self.linear_2.bias)\n",
        "        self.linear_1.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_1.bias)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = self.relu(self.linear_1(embedded))\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.batch_norm(x)\n",
        "        x = x.reshape(x.size(0), -1) \n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGxk4GCg9ocp"
      },
      "source": [
        "class CNNModel4(torch.nn.Module):\n",
        "    def __init__(self, transformer_size, dim_in, dim_out):\n",
        "        super(CNNModel4, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(transformer_size, dim_in, sparse=True)\n",
        "        self.conv_1 = torch.nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool2d = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.linear_1 = torch.nn.Linear(dim_in, 128)\n",
        "        self.linear_2 = torch.nn.Linear(2048, 16)\n",
        "        self.linear_3 = torch.nn.Linear(16, dim_out)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        r = 0.5\n",
        "        self.embedding.weight.data.uniform_(r, r)\n",
        "        nn.init.xavier_uniform_(self.conv_1.weight)\n",
        "        nn.init.zeros_(self.conv_1.bias)\n",
        "        nn.init.kaiming_normal_(self.linear_2.weight)\n",
        "        nn.init.zeros_(self.linear_2.bias)\n",
        "        self.linear_1.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_1.bias)\n",
        "        self.linear_3.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_3.bias)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        x = self.relu(self.linear_1(embedded))\n",
        "        x = self.relu(self.conv_1(x))\n",
        "        x = self.max_pool2d(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.relu(self.linear_2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_3(x)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEEFJfajDTvY"
      },
      "source": [
        "class CNNModel5(torch.nn.Module):\n",
        "    def __init__(self, transformer_size, dim_in, dim_out):\n",
        "        super(CNNModel5, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(transformer_size, dim_in, sparse=True)\n",
        "        self.conv_1 = torch.nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool2d = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.linear_1 = torch.nn.Linear(dim_in, 128)\n",
        "        self.linear_2 = torch.nn.Linear(2048, 1024)\n",
        "        self.linear_3 = torch.nn.Linear(1024, 512)\n",
        "        self.linear_4 = torch.nn.Linear(512, 128)\n",
        "        self.linear_5 = torch.nn.Linear(128, dim_out)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        r = 0.5\n",
        "        self.embedding.weight.data.uniform_(r, r)\n",
        "        nn.init.xavier_uniform_(self.conv_1.weight)\n",
        "        nn.init.zeros_(self.conv_1.bias)\n",
        "        nn.init.kaiming_normal_(self.linear_2.weight)\n",
        "        nn.init.zeros_(self.linear_2.bias)\n",
        "        self.linear_1.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_1.bias)\n",
        "        self.linear_3.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_3.bias)\n",
        "        self.linear_4.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_4.bias)\n",
        "        self.linear_5.weight.data.uniform_(-r, r)\n",
        "        nn.init.zeros_(self.linear_5.bias)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        x = self.relu(self.linear_1(embedded))\n",
        "        x = self.relu(self.conv_1(x))\n",
        "        x = self.max_pool2d(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.relu(self.linear_2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_3(x)\n",
        "        x = self.relu(self.linear_4(x))\n",
        "        x = self.linear_5(x)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a25do0LpVcUk"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_trans(_label))\n",
        "         processed_text = torch.tensor(text_to_index(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8f2nM09Fz6"
      },
      "source": [
        "import torch.optim as optim\n",
        "def train_and_get_accuracy(train_d, valid_d, model, epochs = 10, lr = 0.001, BATCH_SIZE = 128):\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  total_accu = None\n",
        "\n",
        "  train_dataloader = DataLoader(train_d, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
        "  valid_dataloader = DataLoader(valid_d, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # training step\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      predited_label = model(text, offsets)\n",
        "      loss = criterion(predited_label, label)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "      optimizer.step()\n",
        "      total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "\n",
        "    # evaluation step\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(valid_dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "\n",
        "    accu_val = total_acc/total_count\n",
        "    \n",
        "  print('Final accuracy: {:f} '.format(accu_val))\n",
        "  return accu_val"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a5Ljx3L91dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7252c355-97f7-4520-f7b8-ef76aebeb7cb"
      },
      "source": [
        "model = CNNModel1(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn1_accu_dav = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn1_accu_dav"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.773638 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7736381977135172"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9_IEzyVHLFi",
        "outputId": "17230b1a-d56d-4c4c-e5ee-98e042d8c1d8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model2 = CNNModel2(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn2_accu_dav = train_and_get_accuracy(train_data, valid_data, model2, epochs = 100)\n",
        "cnn2_accu_dav"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.773638 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7736381977135172"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anw2czkd31aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1850a48c-3643-4e0d-810f-d190fb07c4a4"
      },
      "source": [
        "model = CNNModel3(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn3_accu_dav = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn3_accu_dav"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.783053 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7830531271015467"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Iu_KkM-PWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e481fe01-56c5-45b4-93c6-5e103bfbddf0"
      },
      "source": [
        "model = CNNModel4(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn4_accu_dav = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn4_accu_dav"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.773638 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7736381977135172"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2naZcjmZELBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69839a2c-7f30-440b-fb1b-ed41cd9b8e69"
      },
      "source": [
        "model = CNNModel5(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn5_accu_dav = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn5_accu_dav"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.773638 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7736381977135172"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4az_3EUey3Xg"
      },
      "source": [
        "X_train, X_valid, Y_train, Y_valid= train_test_split(df_was['text'].tolist(),\n",
        "                                                      df_was['class_label'].tolist(),\n",
        "                                                      test_size=0.3)\n",
        "train_data =list(zip(Y_train,X_train))\n",
        "valid_data =list(zip(Y_valid,X_valid))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWhoYgatzLfB"
      },
      "source": [
        "dataset_copy = train_data\n",
        "transformed = build_vocab_from_iterator(torch_tokenizer(dataset_copy), specials=[\"<unk>\"])\n",
        "transformed.set_default_index(transformed[\"<unk>\"])\n",
        "text_to_index = lambda x: transformed(tzr(x))\n",
        "label_trans = lambda x: int(x) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBf3FYPBzkgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fdd41eb-baa3-471a-d435-28b859744d16"
      },
      "source": [
        "model = CNNModel1(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn1_accu_was = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn1_accu_was"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.692588 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.692588092345079"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHkDCrqP0zmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325dcf78-575d-4617-9f17-51add75edfaf"
      },
      "source": [
        "model = CNNModel2(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn1_accu_was = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn1_accu_was"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.003645 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0036452004860267314"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZloEInp7eTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ae962b-680c-44cc-89fa-70933b9a2f08"
      },
      "source": [
        "model = CNNModel3(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn3_accu_was = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn3_accu_was"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.184690 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18469015795868773"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESJEHWeBTGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26dda94-6d0f-42c8-891e-000a00492b34"
      },
      "source": [
        "model = CNNModel4(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn4_accu_was = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn4_accu_was"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.303767 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3037667071688943"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-wTP7IEXNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720b60f7-dece-4495-a91b-f5f06b26e3e0"
      },
      "source": [
        "model = CNNModel5(len(transformed), 1000, len(set([label for (label, text) in dataset_copy]))).to(device)\n",
        "cnn5_accu_was = train_and_get_accuracy(train_data, valid_data, model)\n",
        "cnn5_accu_was"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.003645 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0036452004860267314"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo4n6-8ALmRk"
      },
      "source": [
        "Models on Waseem dataset perform poorly because there is only 2k instances. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWvmTnjLLrT4"
      },
      "source": [
        "# TODO: what if we shuffled the data a bit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}